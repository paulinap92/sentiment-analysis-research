{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning DistilBERT on Your Dataset (Single-Dataset Notebook)\n",
    "\n",
    "## What this notebook does\n",
    "- Loads **your dataset only** (`DATA_REVIEWS`)\n",
    "- Splits into train/validation (stratified)\n",
    "- Fine-tunes **DistilBERT base** (`distilbert-base-uncased`) for binary sentiment classification\n",
    "- Saves the fine-tuned model locally (so you do **not** retrain next time)\n",
    "- Evaluates on the validation split with:\n",
    "  - full `classification_report` (per-class precision/recall/F1)\n",
    "  - confusion matrix\n",
    "  - error analysis table (longest misclassified reviews)\n",
    "\n",
    "## Notes\n",
    "- This notebook intentionally **does not** use `DATA_REVIEWS_REAL`.\n",
    "- You can create a separate evaluation notebook later if you want cross-dataset generalization checks.\n"
   ],
   "id": "9c4db21c0547d18f"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T10:03:43.701206200Z",
     "start_time": "2026-02-19T10:02:44.794558700Z"
    }
   },
   "source": [
    "# ============================================\n",
    "# 1) Imports & setup\n",
    "# ============================================\n",
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding,\n",
    "    pipeline,\n",
    ")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 140)\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n"
   ],
   "id": "617acddca4500851",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ppiotrowska\\.virtualenvs\\sentiment_service_ML_pipeline-V5O88grN\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Path and expected schema\n",
    "TSV is expected to contain:\n",
    "- `Review` (text)\n",
    "- `Liked` (label: `1` positive, `0` negative)\n"
   ],
   "id": "4e3413df7ce9ebcd"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T10:03:43.721476300Z",
     "start_time": "2026-02-19T10:03:43.707203200Z"
    }
   },
   "source": [
    "# ============================================\n",
    "# 2) Path (EDIT IF NEEDED)\n",
    "# ============================================\n",
    "DATA_REVIEWS_PATH = \"data/reviews_dataset.tsv\"\n",
    "SEP = \"\\t\"\n"
   ],
   "id": "2602b89dd9547ad",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T10:03:43.943903400Z",
     "start_time": "2026-02-19T10:03:43.723813100Z"
    }
   },
   "source": [
    "# ============================================\n",
    "# 3) Load dataset\n",
    "# ============================================\n",
    "def load_reviews_tsv(path: str, sep: str = \"\\t\") -> pd.DataFrame:\n",
    "    df = pd.read_csv(path, sep=sep)\n",
    "    required = {\"Review\", \"Liked\"}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns in {path}: {missing}. Expected at least {required}.\")\n",
    "    df = df.copy()\n",
    "    df[\"Review\"] = df[\"Review\"].fillna(\"\").astype(str)\n",
    "    df[\"Liked\"] = df[\"Liked\"].astype(int)\n",
    "    return df\n",
    "\n",
    "df = load_reviews_tsv(DATA_REVIEWS_PATH, sep=SEP)\n",
    "\n",
    "print(\"DATA_REVIEWS:\", df.shape)\n",
    "display(df.head(5))\n",
    "\n",
    "print(\"\\nLabel distribution (0/1):\")\n",
    "print(df[\"Liked\"].value_counts().to_dict())\n"
   ],
   "id": "6e5572f9ca761583",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_REVIEWS: (6000, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                              Review  Liked\n",
       "0   I expected confusing, not this: impressive fans.      1\n",
       "1  Not impressive at all — the check-in was actua...      0\n",
       "2  I absolutely liked the drinks; it was outstand...      1\n",
       "3     a pleasant surprise. The fans felt impressive.      1\n",
       "4  I thought it would be pleasant, but it was not...      0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I expected confusing, not this: impressive fans.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not impressive at all — the check-in was actua...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I absolutely liked the drinks; it was outstand...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a pleasant surprise. The fans felt impressive.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I thought it would be pleasant, but it was not...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label distribution (0/1):\n",
      "{1: 3000, 0: 3000}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Train/validation split\n",
    "We use a stratified split to preserve the label ratio.\n"
   ],
   "id": "45ba9409c0df6e9a"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T10:03:44.127725Z",
     "start_time": "2026-02-19T10:03:44.063959900Z"
    }
   },
   "source": [
    "# ============================================\n",
    "# 4) Train/val split\n",
    "# ============================================\n",
    "train_df, val_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    random_state=SEED,\n",
    "    stratify=df[\"Liked\"]\n",
    ")\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df   = val_df.reset_index(drop=True)\n",
    "\n",
    "print(\"train:\", train_df.shape, \"val:\", val_df.shape)\n"
   ],
   "id": "fb31a1679332604f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (4800, 2) val: (1200, 2)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Tokenization and HF datasets\n",
    "Speed tips:\n",
    "- Reduce `MAX_LENGTH` (128/256)\n",
    "- Keep epochs low (1–2) on CPU\n"
   ],
   "id": "8c71375b04957ed"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T10:03:46.674346400Z",
     "start_time": "2026-02-19T10:03:44.140721Z"
    }
   },
   "source": [
    "# ============================================\n",
    "# 5) Tokenization + HF datasets\n",
    "# ============================================\n",
    "BASE_MODEL = \"distilbert-base-uncased\"\n",
    "OUT_DIR = \"./models/finetuned_distilbert_data_reviews\"\n",
    "\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 5\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "def to_hf_dataset(df_in: pd.DataFrame) -> Dataset:\n",
    "    ds = Dataset.from_pandas(df_in)\n",
    "    ds = ds.rename_column(\"Liked\", \"labels\")\n",
    "\n",
    "    def tokenize_batch(batch):\n",
    "        return tokenizer(batch[\"Review\"], truncation=True, max_length=MAX_LENGTH)\n",
    "\n",
    "    ds = ds.map(tokenize_batch, batched=True)\n",
    "\n",
    "    keep = {\"input_ids\", \"attention_mask\", \"labels\"}\n",
    "    remove_cols = [c for c in ds.column_names if c not in keep]\n",
    "    if remove_cols:\n",
    "        ds = ds.remove_columns(remove_cols)\n",
    "\n",
    "    ds.set_format(type=\"torch\")\n",
    "    return ds\n",
    "\n",
    "train_ds = to_hf_dataset(train_df)\n",
    "val_ds   = to_hf_dataset(val_df)\n",
    "\n",
    "print(\"train_ds:\", train_ds.num_rows, \"val_ds:\", val_ds.num_rows)\n"
   ],
   "id": "ff4225d0f9070b3f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4800/4800 [00:00<00:00, 23795.16 examples/s]\n",
      "Map: 100%|██████████| 1200/1200 [00:00<00:00, 5186.40 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_ds: 4800 val_ds: 1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Metrics\n"
   ],
   "id": "c6bcba059eb0c6c"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T10:03:47.398588Z",
     "start_time": "2026-02-19T10:03:47.380652800Z"
    }
   },
   "source": [
    "# ============================================\n",
    "# 6) Metrics (macro)\n",
    "# ============================================\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(labels, preds, average=\"macro\", zero_division=0)\n",
    "    return {\"accuracy\": acc, \"precision_macro\": p, \"recall_macro\": r, \"f1_macro\": f1}\n"
   ],
   "id": "355f5253f5d3847",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Fine-tune DistilBERT\n",
    "This is the only slow cell.\n"
   ],
   "id": "7886bf621e8c418f"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T10:45:54.458518800Z",
     "start_time": "2026-02-19T10:03:47.401591300Z"
    }
   },
   "source": [
    "# ============================================\n",
    "# 7) Fine-tuning\n",
    "# ============================================\n",
    "model = AutoModelForSequenceClassification.from_pretrained(BASE_MODEL, num_labels=2)\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"./results_finetune_data_reviews\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=100,\n",
    "    seed=SEED,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.evaluate()\n"
   ],
   "id": "bf1131b82f788446",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|██████████| 100/100 [00:00<00:00, 243.84it/s, Materializing param=distilbert.transformer.layer.5.sa_layer_norm.weight]   \n",
      "\u001B[1mDistilBertForSequenceClassification LOAD REPORT\u001B[0m from: distilbert-base-uncased\n",
      "Key                     | Status     | \n",
      "------------------------+------------+-\n",
      "vocab_layer_norm.bias   | UNEXPECTED | \n",
      "vocab_projector.bias    | UNEXPECTED | \n",
      "vocab_transform.weight  | UNEXPECTED | \n",
      "vocab_transform.bias    | UNEXPECTED | \n",
      "vocab_layer_norm.weight | UNEXPECTED | \n",
      "classifier.weight       | MISSING    | \n",
      "pre_classifier.weight   | MISSING    | \n",
      "pre_classifier.bias     | MISSING    | \n",
      "classifier.bias         | MISSING    | \n",
      "\n",
      "\u001B[3mNotes:\n",
      "- UNEXPECTED\u001B[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001B[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001B[0m\n",
      "C:\\Users\\ppiotrowska\\.virtualenvs\\sentiment_service_ML_pipeline-V5O88grN\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  super().__init__(loader)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 41:28, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000978</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "3a381ff8778182036a6354f59bdc60dc"
     }
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ppiotrowska\\.virtualenvs\\sentiment_service_ML_pipeline-V5O88grN\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  super().__init__(loader)\n",
      "C:\\Users\\ppiotrowska\\.virtualenvs\\sentiment_service_ML_pipeline-V5O88grN\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  super().__init__(loader)\n",
      "C:\\Users\\ppiotrowska\\.virtualenvs\\sentiment_service_ML_pipeline-V5O88grN\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  super().__init__(loader)\n",
      "C:\\Users\\ppiotrowska\\.virtualenvs\\sentiment_service_ML_pipeline-V5O88grN\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  super().__init__(loader)\n",
      "C:\\Users\\ppiotrowska\\.virtualenvs\\sentiment_service_ML_pipeline-V5O88grN\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  super().__init__(loader)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75/75 00:34]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "1d59ea0f4b63e606197a6e93fcad6b5b"
     }
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 5.578479976975359e-05,\n",
       " 'eval_accuracy': 1.0,\n",
       " 'eval_precision_macro': 1.0,\n",
       " 'eval_recall_macro': 1.0,\n",
       " 'eval_f1_macro': 1.0,\n",
       " 'eval_runtime': 34.8746,\n",
       " 'eval_samples_per_second': 34.409,\n",
       " 'eval_steps_per_second': 2.151,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Save model locally\n"
   ],
   "id": "4d980f3f1da020d0"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T10:45:55.457292900Z",
     "start_time": "2026-02-19T10:45:54.648431900Z"
    }
   },
   "source": [
    "# ============================================\n",
    "# 8) Save model locally\n",
    "# ============================================\n",
    "import os\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "trainer.save_model(OUT_DIR)\n",
    "tokenizer.save_pretrained(OUT_DIR)\n",
    "\n",
    "print(\"Saved fine-tuned model to:\", OUT_DIR)\n"
   ],
   "id": "64e8c8049b4bde06",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing model shards: 100%|██████████| 1/1 [00:00<00:00,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved fine-tuned model to: ./models/finetuned_distilbert_data_reviews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Evaluate on validation split (sequential style)\n",
    "We generate:\n",
    "- classification report\n",
    "- confusion matrix\n",
    "- error analysis table\n"
   ],
   "id": "fdd36b607c2e8ded"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T10:46:19.451550300Z",
     "start_time": "2026-02-19T10:45:55.518878600Z"
    }
   },
   "source": [
    "# ============================================\n",
    "# 9) Validation evaluation (pipeline)\n",
    "# ============================================\n",
    "ft_clf = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=OUT_DIR,\n",
    "    tokenizer=OUT_DIR,\n",
    "    device=-1  # CPU; set 0 if you have CUDA GPU\n",
    ")\n",
    "\n",
    "texts = val_df[\"Review\"].fillna(\"\").astype(str).tolist()\n",
    "y_true = val_df[\"Liked\"].astype(int).tolist()\n",
    "\n",
    "preds = ft_clf(texts, batch_size=32, truncation=True, max_length=MAX_LENGTH)\n",
    "y_pred = [1 if p[\"label\"] == \"POSITIVE\" else 0 for p in preds]\n",
    "\n",
    "print(\"=== Fine-tuned classification report (VAL) ===\")\n",
    "print(classification_report(y_true, y_pred, digits=4))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm_df = pd.DataFrame(cm, index=[\"true_0\",\"true_1\"], columns=[\"pred_0\",\"pred_1\"])\n",
    "print(\"\\n=== Confusion matrix (VAL) ===\")\n",
    "display(cm_df)\n",
    "\n",
    "val_acc = accuracy_score(y_true, y_pred)\n",
    "print(\"\\nVAL accuracy:\", val_acc)\n"
   ],
   "id": "a3b9cf8ebe65cc74",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 104/104 [00:00<00:00, 191.08it/s, Materializing param=pre_classifier.weight]                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Fine-tuned classification report (VAL) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5000    1.0000    0.6667       600\n",
      "           1     0.0000    0.0000    0.0000       600\n",
      "\n",
      "    accuracy                         0.5000      1200\n",
      "   macro avg     0.2500    0.5000    0.3333      1200\n",
      "weighted avg     0.2500    0.5000    0.3333      1200\n",
      "\n",
      "\n",
      "=== Confusion matrix (VAL) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ppiotrowska\\.virtualenvs\\sentiment_service_ML_pipeline-V5O88grN\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\ppiotrowska\\.virtualenvs\\sentiment_service_ML_pipeline-V5O88grN\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\ppiotrowska\\.virtualenvs\\sentiment_service_ML_pipeline-V5O88grN\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "        pred_0  pred_1\n",
       "true_0     600       0\n",
       "true_1     600       0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true_0</th>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_1</th>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VAL accuracy: 0.5\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T10:46:19.593217300Z",
     "start_time": "2026-02-19T10:46:19.497119400Z"
    }
   },
   "source": [
    "# ============================================\n",
    "# 10) Error analysis (VAL)\n",
    "# ============================================\n",
    "out = val_df.copy()\n",
    "out[\"y_true\"] = y_true\n",
    "out[\"y_pred\"] = y_pred\n",
    "out[\"is_error\"] = out[\"y_true\"] != out[\"y_pred\"]\n",
    "\n",
    "err = out[out[\"is_error\"]].copy()\n",
    "err[\"review_len\"] = err[\"Review\"].astype(str).str.len()\n",
    "\n",
    "print(\"Errors (VAL):\", len(err), \"/\", len(val_df))\n",
    "display(err.sort_values(\"review_len\", ascending=False).head(20)[[\"y_true\",\"y_pred\",\"review_len\",\"Review\"]])\n"
   ],
   "id": "6c9b4654f88a6066",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors (VAL): 600 / 1200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      y_true  y_pred  review_len                                             Review\n",
       "47         1       0         140  The performance started outstanding; even thou...\n",
       "576        1       0         130  absolutely coherent at first, however it becam...\n",
       "338        1       0         128  The lights started outstanding; even though th...\n",
       "690        1       0         127  The atmosphere started pleasant; yet the setli...\n",
       "252        1       0         126  The performance started pleasant; even though ...\n",
       "936        1       0         126  The dessert started outstanding; however the r...\n",
       "230        1       0         125  The ending started outstanding; although the c...\n",
       "773        1       0         120  The flight was outstanding, even though the ch...\n",
       "246        1       0         120  I loved the cinematography, even though the di...\n",
       "388        1       0         120  really excellent at first, however it became c...\n",
       "1063       1       0         120  The transfer started coherent; but the locatio...\n",
       "1173       1       0         120  The dessert started excellent; yet the reserva...\n",
       "957        1       0         119  really pleasant at first, although it became t...\n",
       "108        1       0         119  honestly engaging at first, even though it bec...\n",
       "1144       1       0         118  quite smooth at first, although it became bori...\n",
       "190        1       0         118  honestly fantastic at first, although it becam...\n",
       "131        1       0         118  honestly coherent at first, however it became ...\n",
       "444        1       0         117  The lights started outstanding; yet the perfor...\n",
       "1138       1       0         117  really solid at first, even though it became a...\n",
       "953        1       0         116  The dessert was excellent, although the servic..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>review_len</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>The performance started outstanding; even thou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>absolutely coherent at first, however it becam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>The lights started outstanding; even though th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>The atmosphere started pleasant; yet the setli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>The performance started pleasant; even though ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>The dessert started outstanding; however the r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>The ending started outstanding; although the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>The flight was outstanding, even though the ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>I loved the cinematography, even though the di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>really excellent at first, however it became c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>The transfer started coherent; but the locatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>The dessert started excellent; yet the reserva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>really pleasant at first, although it became t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>honestly engaging at first, even though it bec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>quite smooth at first, although it became bori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>honestly fantastic at first, although it becam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>honestly coherent at first, however it became ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>The lights started outstanding; yet the perfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>really solid at first, even though it became a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>The dessert was excellent, although the servic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11) Load the saved model later (no retraining)\n",
    "Use this snippet in any notebook/script:\n"
   ],
   "id": "112cf397d281b5e"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T10:46:20.120891500Z",
     "start_time": "2026-02-19T10:46:19.644353300Z"
    }
   },
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "clf = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"./models/finetuned_distilbert_data_reviews\",\n",
    "    tokenizer=\"./models/finetuned_distilbert_data_reviews\",\n",
    "    device=-1\n",
    ")\n",
    "\n",
    "clf(\"This product is amazing!\")\n"
   ],
   "id": "c9be3260829c9eba",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 104/104 [00:00<00:00, 384.54it/s, Materializing param=pre_classifier.weight]                                  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.999537467956543}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
