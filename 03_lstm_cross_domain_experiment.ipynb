{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-domain vs. in-domain evaluation (what it means)\n",
    "\n",
    "**Domain** = the “type” of text data: writing style, vocabulary, source, topic, and label patterns.\n",
    "\n",
    "- **In-domain** evaluation: train and test on the same dataset distribution.\n",
    "  Example: `train on DATA_REVIEWS_REAL → test on DATA_REVIEWS_REAL`.\n",
    "- **Cross-domain** evaluation: train on one dataset, test on a different dataset distribution.\n",
    "  Example: `train on DATA_REVIEWS_REAL → test on DATA_REVIEWS`.\n",
    "\n",
    "Cross-domain results are a practical way to measure **generalization** and detect **domain shift** (performance drop caused by differences in data distribution).\n",
    "\n",
    "---\n",
    "\n",
    "## How the LSTM model works (very short)\n",
    "\n",
    "Architecture used in the notebook:\n",
    "\n",
    "`Embedding → LSTM → Linear → Softmax`\n",
    "\n",
    "1. **Embedding** maps token IDs to dense vectors.\n",
    "2. **LSTM** processes the sequence step-by-step and maintains a memory state using gates:\n",
    "   - **Forget gate**: what to discard\n",
    "   - **Input gate**: what to store\n",
    "   - **Output gate**: what to expose as output\n",
    "   This helps capture word order and longer dependencies (e.g., negations like “not good”).\n",
    "3. **Linear layer** takes the final hidden state (sentence representation) and outputs logits for classes `{0, 1}`.\n",
    "\n",
    "Training setup (high level):\n",
    "- `CrossEntropyLoss`, `Adam`, gradient clipping\n",
    "- stratified split into train/validation\n",
    "- evaluation on both in-domain and cross-domain sets\n",
    "\n",
    "---\n",
    "\n",
    "## LSTM vs Transformer (quick comparison)\n",
    "\n",
    "### Sequence processing\n",
    "- **LSTM** reads tokens **sequentially** (step-by-step).\n",
    "- **Transformer** reads tokens **in parallel** using **self-attention**.\n",
    "\n",
    "### Capturing context\n",
    "- **LSTM** stores information in a hidden state; long-range dependencies can be harder.\n",
    "- **Transformer** uses self-attention to directly relate any token to any other token, which typically improves handling of:\n",
    "  - long sentences\n",
    "  - negation/sarcasm\n",
    "  - complex context interactions\n",
    "\n",
    "### Generalization across domains\n",
    "- **LSTM (with simple tokenization + small vocab)** is often more sensitive to domain shift because it relies heavily on surface-level patterns and vocabulary overlap.\n",
    "- **Transformer (pretrained on massive text corpora)** usually generalizes better cross-domain because it starts with rich language representations learned during pretraining.\n",
    "\n",
    "### Compute / practicality\n",
    "- **LSTM**: lightweight, fast, easier to deploy offline, good baseline and learning model.\n",
    "- **Transformer**: heavier, usually better accuracy, but more compute/memory.\n",
    "\n",
    "---\n",
    "\n",
    "## Why this notebook matters\n",
    "By training on one dataset and evaluating on the other, we explicitly measure:\n",
    "- **in-domain performance** (how well the model fits the training distribution)\n",
    "- **cross-domain performance** (how well it generalizes to different text distributions)\n",
    "\n",
    "A large drop in cross-domain metrics is a strong indicator of **domain shift**.\n"
   ],
   "id": "c454d1c58fedfc59"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T11:27:21.431357700Z",
     "start_time": "2026-02-19T11:27:16.706023800Z"
    }
   },
   "source": [
    "# ============================================\n",
    "# 1) Imports & reproducibility\n",
    "# ============================================\n",
    "import re\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ],
   "id": "a118fa8d829b835a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T11:27:21.588345500Z",
     "start_time": "2026-02-19T11:27:21.434354700Z"
    }
   },
   "source": [
    "# ============================================\n",
    "# 2) Load datasets (TSV)\n",
    "# ============================================\n",
    "REAL_PATH  = \"data/reviews_dataset_real.tsv\"\n",
    "SMALL_PATH = \"data/reviews_dataset.tsv\"\n",
    "\n",
    "df_real  = pd.read_csv(REAL_PATH,  sep=\"\\t\")\n",
    "df_small = pd.read_csv(SMALL_PATH, sep=\"\\t\")\n",
    "\n",
    "for df in (df_real, df_small):\n",
    "    df[\"Review\"] = df[\"Review\"].fillna(\"\").astype(str)\n",
    "    df[\"Liked\"]  = df[\"Liked\"].astype(int)\n",
    "    df.dropna(subset=[\"Review\",\"Liked\"], inplace=True)\n",
    "\n",
    "print(\"REAL :\", df_real.shape)\n",
    "print(\"SMALL:\", df_small.shape)\n",
    "\n",
    "print(\"\\nLabel distribution:\")\n",
    "print(\"REAL :\", df_real[\"Liked\"].value_counts().to_dict())\n",
    "print(\"SMALL:\", df_small[\"Liked\"].value_counts().to_dict())\n"
   ],
   "id": "35fdca4e889903cf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REAL : (68221, 3)\n",
      "SMALL: (6000, 2)\n",
      "\n",
      "Label distribution:\n",
      "REAL : {1: 38013, 0: 30208}\n",
      "SMALL: {1: 3000, 0: 3000}\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T11:27:21.611396900Z",
     "start_time": "2026-02-19T11:27:21.591346Z"
    }
   },
   "source": [
    "# ============================================\n",
    "# 3) Tokenization & vocabulary\n",
    "# ============================================\n",
    "TOKEN_RE = re.compile(r\"[^a-zA-Z0-9\\s']+\")\n",
    "\n",
    "def tokenize(text: str) -> list[str]:\n",
    "    text = text.lower().strip()\n",
    "    text = TOKEN_RE.sub(\" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.split() if text else []\n",
    "\n",
    "def build_vocab(texts, min_freq: int = 2) -> dict[str,int]:\n",
    "    vocab = {\"<pad>\": 0, \"<unk>\": 1}\n",
    "    counts = {}\n",
    "    for t in texts:\n",
    "        for w in tokenize(t):\n",
    "            counts[w] = counts.get(w, 0) + 1\n",
    "    idx = 2\n",
    "    for w, c in sorted(counts.items(), key=lambda x: (-x[1], x[0])):\n",
    "        if c >= min_freq:\n",
    "            vocab[w] = idx\n",
    "            idx += 1\n",
    "    return vocab\n"
   ],
   "id": "19850b729cba62ca",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T11:27:21.637573300Z",
     "start_time": "2026-02-19T11:27:21.614393700Z"
    }
   },
   "source": [
    "# ============================================\n",
    "# 4) Dataset, collate (padding), config\n",
    "# ============================================\n",
    "@dataclass\n",
    "class Config:\n",
    "    max_len: int = 120\n",
    "    batch_size: int = 64\n",
    "    emb_dim: int = 128\n",
    "    hid_dim: int = 128\n",
    "    lr: float = 1e-3\n",
    "    epochs: int = 5\n",
    "\n",
    "cfg = Config()\n",
    "\n",
    "class ReviewsDataset(Dataset):\n",
    "    def __init__(self, texts, labels, vocab):\n",
    "        self.texts = list(texts)\n",
    "        self.labels = list(labels)\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens = tokenize(self.texts[idx])[:cfg.max_len]\n",
    "        ids = [self.vocab.get(w, 1) for w in tokens]  # 1 = <unk>\n",
    "        if len(ids) == 0:\n",
    "            ids = [1]\n",
    "        return torch.tensor(ids, dtype=torch.long), torch.tensor(int(self.labels[idx]), dtype=torch.long)\n",
    "\n",
    "def collate_fn(batch, pad_id: int = 0):\n",
    "    xs, ys = zip(*batch)\n",
    "    lengths = torch.tensor([len(x) for x in xs], dtype=torch.long)\n",
    "    max_len = int(lengths.max().item())\n",
    "    padded = torch.full((len(xs), max_len), fill_value=pad_id, dtype=torch.long)\n",
    "    for i, x in enumerate(xs):\n",
    "        padded[i, :len(x)] = x\n",
    "    return padded, lengths, torch.stack(ys)\n"
   ],
   "id": "3ac61108b8e6f156",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T11:27:21.677380Z",
     "start_time": "2026-02-19T11:27:21.642572100Z"
    }
   },
   "source": [
    "# ============================================\n",
    "# 5) Model\n",
    "# ============================================\n",
    "class SentimentLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size: int):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, cfg.emb_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(cfg.emb_dim, cfg.hid_dim, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(cfg.hid_dim, 2)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        emb = self.dropout(self.embedding(x))\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            emb, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        _, (h, _) = self.lstm(packed)\n",
    "        logits = self.fc(self.dropout(h[-1]))\n",
    "        return logits\n"
   ],
   "id": "c32a91ceb0ce8f17",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T11:27:21.689728Z",
     "start_time": "2026-02-19T11:27:21.678381500Z"
    }
   },
   "source": [
    "# ============================================\n",
    "# 6) Split helper (train/val/test)\n",
    "# ============================================\n",
    "def split_train_val_test(df: pd.DataFrame, test_size=0.2, val_size=0.1):\n",
    "    # First split off TEST\n",
    "    X = df[\"Review\"].tolist()\n",
    "    y = df[\"Liked\"].tolist()\n",
    "    X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=SEED, stratify=y\n",
    "    )\n",
    "    # Then split TRAIN vs VAL from the remaining\n",
    "    # val_size is relative to trainval, not the original dataset\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_trainval, y_trainval, test_size=val_size, random_state=SEED, stratify=y_trainval\n",
    "    )\n",
    "    return (X_train, y_train), (X_val, y_val), (X_test, y_test)\n"
   ],
   "id": "1377ba5b35cdd1d0",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T11:27:21.718395400Z",
     "start_time": "2026-02-19T11:27:21.692734200Z"
    }
   },
   "source": [
    "# ============================================\n",
    "# 7) Training & evaluation (test-only metrics)\n",
    "# ============================================\n",
    "def make_loader(texts, labels, vocab, shuffle: bool):\n",
    "    ds = ReviewsDataset(texts, labels, vocab)\n",
    "    return DataLoader(ds, batch_size=cfg.batch_size, shuffle=shuffle, collate_fn=collate_fn)\n",
    "\n",
    "def train_on_split(X_train, y_train, X_val, y_val):\n",
    "    # Build vocab ONLY from training text (no peeking)\n",
    "    vocab = build_vocab(X_train, min_freq=2)\n",
    "\n",
    "    model = SentimentLSTM(len(vocab)).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=cfg.lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    train_loader = make_loader(X_train, y_train, vocab, shuffle=True)\n",
    "    val_loader   = make_loader(X_val,   y_val,   vocab, shuffle=False)\n",
    "\n",
    "    best_val_acc = -1.0\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(1, cfg.epochs + 1):\n",
    "        # ---- train ----\n",
    "        model.train()\n",
    "        for x, lengths, y in train_loader:\n",
    "            x, lengths, y = x.to(device), lengths.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(x, lengths)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "        # ---- validate (sanity) ----\n",
    "        model.eval()\n",
    "        all_p, all_t = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, lengths, y in val_loader:\n",
    "                x, lengths = x.to(device), lengths.to(device)\n",
    "                logits = model(x, lengths)\n",
    "                preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "                all_p.extend(preds)\n",
    "                all_t.extend(y.numpy())\n",
    "        val_acc = accuracy_score(all_t, all_p)\n",
    "        print(f\"Epoch {epoch}/{cfg.epochs} | val_acc={val_acc:.4f}\")\n",
    "\n",
    "        # Keep best model by validation accuracy\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "    # Restore best weights\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    return model, vocab, best_val_acc\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_on_test(model, vocab, X_test, y_test, title: str):\n",
    "    loader = make_loader(X_test, y_test, vocab, shuffle=False)\n",
    "    model.eval()\n",
    "\n",
    "    all_preds, all_true = [], []\n",
    "    for x, lengths, y in loader:\n",
    "        x, lengths = x.to(device), lengths.to(device)\n",
    "        logits = model(x, lengths)\n",
    "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_true.extend(y.numpy())\n",
    "\n",
    "    acc = accuracy_score(all_true, all_preds)\n",
    "    print(f\"=== {title} ===\")\n",
    "    print(\"Test accuracy:\", acc)\n",
    "    print(classification_report(all_true, all_preds, digits=4))\n",
    "    print(\"Confusion matrix:\\n\", confusion_matrix(all_true, all_preds))\n",
    "    return acc\n"
   ],
   "id": "8da645a4fc6806b9",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Create splits for both datasets"
   ],
   "id": "599e7ea7725b7d5d"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T11:27:21.844376700Z",
     "start_time": "2026-02-19T11:27:21.733934300Z"
    }
   },
   "source": [
    "# REAL splits\n",
    "(real_train, real_y_train), (real_val, real_y_val), (real_test, real_y_test) = split_train_val_test(df_real)\n",
    "\n",
    "# SMALL splits\n",
    "(small_train, small_y_train), (small_val, small_y_val), (small_test, small_y_test) = split_train_val_test(df_small)\n",
    "\n",
    "print(\"REAL  :\", len(real_train), len(real_val), len(real_test))\n",
    "print(\"SMALL :\", len(small_train), len(small_val), len(small_test))\n"
   ],
   "id": "19a4946d50405381",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REAL  : 49118 5458 13645\n",
      "SMALL : 4320 480 1200\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Experiment A — Train on REAL, test on REAL and SMALL (test splits only)"
   ],
   "id": "b209b1fd15edc6df"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T11:31:44.585429800Z",
     "start_time": "2026-02-19T11:27:21.847376700Z"
    }
   },
   "source": [
    "model_real, vocab_real, best_val_real = train_on_split(real_train, real_y_train, real_val, real_y_val)\n",
    "\n",
    "acc_rr = evaluate_on_test(model_real, vocab_real, real_test,  real_y_test,  \"Train REAL → Test REAL\")\n",
    "acc_rs = evaluate_on_test(model_real, vocab_real, small_test, small_y_test, \"Train REAL → Test SMALL\")\n"
   ],
   "id": "2aa53024ade5ca6d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | val_acc=0.8318\n",
      "Epoch 2/5 | val_acc=0.8835\n",
      "Epoch 3/5 | val_acc=0.9007\n",
      "Epoch 4/5 | val_acc=0.9095\n",
      "Epoch 5/5 | val_acc=0.9093\n",
      "=== Train REAL → Test REAL ===\n",
      "Test accuracy: 0.9057530230853793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8940    0.8931    0.8935      6042\n",
      "           1     0.9151    0.9158    0.9155      7603\n",
      "\n",
      "    accuracy                         0.9058     13645\n",
      "   macro avg     0.9045    0.9045    0.9045     13645\n",
      "weighted avg     0.9057    0.9058    0.9057     13645\n",
      "\n",
      "Confusion matrix:\n",
      " [[5396  646]\n",
      " [ 640 6963]]\n",
      "=== Train REAL → Test SMALL ===\n",
      "Test accuracy: 0.7066666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7116    0.6950    0.7032       600\n",
      "           1     0.7020    0.7183    0.7100       600\n",
      "\n",
      "    accuracy                         0.7067      1200\n",
      "   macro avg     0.7068    0.7067    0.7066      1200\n",
      "weighted avg     0.7068    0.7067    0.7066      1200\n",
      "\n",
      "Confusion matrix:\n",
      " [[417 183]\n",
      " [169 431]]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) Experiment B — Train on SMALL, test on SMALL and REAL (test splits only)"
   ],
   "id": "b21c25d39cad8067"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T11:32:03.393647Z",
     "start_time": "2026-02-19T11:31:45.464695600Z"
    }
   },
   "source": [
    "model_small, vocab_small, best_val_small = train_on_split(small_train, small_y_train, small_val, small_y_val)\n",
    "\n",
    "acc_ss = evaluate_on_test(model_small, vocab_small, small_test, small_y_test, \"Train SMALL → Test SMALL\")\n",
    "acc_sr = evaluate_on_test(model_small, vocab_small, real_test,  real_y_test,  \"Train SMALL → Test REAL\")\n"
   ],
   "id": "4ea64ff49f6ccdc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 | val_acc=1.0000\n",
      "Epoch 2/5 | val_acc=1.0000\n",
      "Epoch 3/5 | val_acc=1.0000\n",
      "Epoch 4/5 | val_acc=1.0000\n",
      "Epoch 5/5 | val_acc=1.0000\n",
      "=== Train SMALL → Test SMALL ===\n",
      "Test accuracy: 0.9966666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9933    0.9967       600\n",
      "           1     0.9934    1.0000    0.9967       600\n",
      "\n",
      "    accuracy                         0.9967      1200\n",
      "   macro avg     0.9967    0.9967    0.9967      1200\n",
      "weighted avg     0.9967    0.9967    0.9967      1200\n",
      "\n",
      "Confusion matrix:\n",
      " [[596   4]\n",
      " [  0 600]]\n",
      "=== Train SMALL → Test REAL ===\n",
      "Test accuracy: 0.4881641626969586\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4305    0.4831    0.4553      6042\n",
      "           1     0.5451    0.4922    0.5173      7603\n",
      "\n",
      "    accuracy                         0.4882     13645\n",
      "   macro avg     0.4878    0.4876    0.4863     13645\n",
      "weighted avg     0.4944    0.4882    0.4898     13645\n",
      "\n",
      "Confusion matrix:\n",
      " [[2919 3123]\n",
      " [3861 3742]]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11) Summary"
   ],
   "id": "511201ac0e185a78"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-19T11:32:03.476494800Z",
     "start_time": "2026-02-19T11:32:03.429786400Z"
    }
   },
   "source": [
    "summary = pd.DataFrame([\n",
    "    {\"train\":\"REAL\",  \"test\":\"REAL\",  \"test_accuracy\":acc_rr, \"best_val_acc\":best_val_real},\n",
    "    {\"train\":\"REAL\",  \"test\":\"SMALL\", \"test_accuracy\":acc_rs, \"best_val_acc\":best_val_real},\n",
    "    {\"train\":\"SMALL\", \"test\":\"SMALL\", \"test_accuracy\":acc_ss, \"best_val_acc\":best_val_small},\n",
    "    {\"train\":\"SMALL\", \"test\":\"REAL\",  \"test_accuracy\":acc_sr, \"best_val_acc\":best_val_small},\n",
    "])\n",
    "\n",
    "summary\n"
   ],
   "id": "d3845f805364b50c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   train   test  test_accuracy  best_val_acc\n",
       "0   REAL   REAL       0.905753      0.909491\n",
       "1   REAL  SMALL       0.706667      0.909491\n",
       "2  SMALL  SMALL       0.996667      1.000000\n",
       "3  SMALL   REAL       0.488164      1.000000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>best_val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REAL</td>\n",
       "      <td>REAL</td>\n",
       "      <td>0.905753</td>\n",
       "      <td>0.909491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REAL</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>0.909491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMALL</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>0.996667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SMALL</td>\n",
       "      <td>REAL</td>\n",
       "      <td>0.488164</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
